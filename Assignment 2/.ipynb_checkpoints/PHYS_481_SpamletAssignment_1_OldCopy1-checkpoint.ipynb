{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phys 481 Fall 2021 Assignment 1: Spamlet\n",
    "### A.G. Swadling (30098501)\n",
    "### E.J. Thompson (30087678)\n",
    "### G.J. Gelinas (30085897)\n",
    "### T.J. Cey (30088060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries for numerical methods and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load libraries for reading from a url and handling large numbers\n",
    "import urllib.request\n",
    "import mpmath as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "## Question 1:\n",
    "\n",
    "In this question we determine the Shannon Entropy of Spamlet in bits per character, using the probabilities of different characters occuring in Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonEntropy(probs):\n",
    "    \"\"\"Returns the shannon entropy associated with a collection of probabilities\"\"\"\n",
    "    \n",
    "    # Obtains the probability associated with all the items in the probs dictionary\n",
    "    prob_values = list(probs.values())\n",
    "    \n",
    "    # Calculates the shannon entropy\n",
    "    entropy = -sum(np.log2(prob_values)*prob_values)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictProbs(itemDict):\n",
    "    \"\"\"Returns a dictionary of probabilities associated with the occurences of characters in a file\"\"\"\n",
    "    \n",
    "    # Total number of occurences\n",
    "    total = sum(itemDict.values())\n",
    "    \n",
    "    # Initializes probability dictionary\n",
    "    probs = {}\n",
    "    \n",
    "    # Gets the count of each character and adds its simple probability to the array\n",
    "    for item in itemDict.keys():\n",
    "        probs[item] = (1.0*itemDict[item]/total)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleCharDecode(url):\n",
    "    \"\"\"Reads the data from a url and decodes it into characters before sorting it into a dictionary\"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "    \n",
    "    # Creates a dictionary counting the number of times each character occurs\n",
    "    charDict = {}\n",
    "    for char in charlist:\n",
    "        # Increments the character's dictionary value if it is already stored, \n",
    "        # and initializes it at one otherwise\n",
    "        if char in charDict.keys():\n",
    "            charDict[char] += 1\n",
    "        else:\n",
    "            charDict[char] = 1\n",
    "    \n",
    "    return charDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of Spamlet in bits per character is: 4.095554914480837\n"
     ]
    }
   ],
   "source": [
    "# Obtain spamlet data\n",
    "url = r'http://www.gutenberg.org/files/1524/1524-0.txt'\n",
    "\n",
    "# Obtains the character dictionary and associated probability dictionary for calculating the shannon entropy\n",
    "charDict = singleCharDecode(url)\n",
    "charProbs = dictProbs(charDict)\n",
    "entropy = shannonEntropy(charProbs)\n",
    "\n",
    "print(\"The entropy of Spamlet in bits per character is:\", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we observe that the Shannon Entropy for Spamlet in bits per character is approximately 4.0955549."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 2:\n",
    "\n",
    "In this question we determine the probability of a monkey typing Spamlet on a keyboard consisting of the 26 letter characters, and a spacebar, where all 27 characters are equally probable. In particular, we determine the number of 27-key sequences of length 184730 (the length of Spamlet after removing double spaces), and we determine the probability of any one of these sequences being typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_sequences(num_options, length):\n",
    "    \"\"\"Returns the number of sequences of a certain length given that each entry has num_options choices\"\"\"\n",
    "    \n",
    "    return mp.power(num_options,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_total(num_options, length):\n",
    "    \"\"\"Returns the probability of obtaining a particular sequence of characters of length 'length'\n",
    "    from a selection of 'num_options' symbols.\"\"\"\n",
    "    \n",
    "    return mp.power(num_options, -length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sequences of length 184730 made up 27-keys is 6.73213923799414e+264415\n",
      "The probability of any one such sequence occuring is 1.4854119391297e-264416\n"
     ]
    }
   ],
   "source": [
    "# Obtains the character dictionary and its length\n",
    "charDict = singleCharDecode(url)\n",
    "length = sum(charDict.values())\n",
    "\n",
    "# Obtains the number of sequences and the probability of any given sequence \n",
    "# of length equal to Spamlet for the 26 letter characters and space\n",
    "sequenceNum = num_sequences(27, length)\n",
    "probTot = prob_total(27, length)\n",
    "\n",
    "print(\"The number of sequences of length\", length, \"made up 27-keys is\", sequenceNum)\n",
    "print(\"The probability of any one such sequence occuring is\", probTot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have that if the monkey presses the 27-keys with equal probability, the number of possible sequences is approximately $6.732139E+264415$, with each sequence having a probability of $1.4854119E-264416$ of being typed at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "We now investigate how the probability of a monkey typing Spamlet changes if the key probabilities are not uniform but instead the probability of hitting any given key is the same as the probability of selecting that key at random out of Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_selection(probs, occurences):\n",
    "    \"\"\"\n",
    "    Returns the probability of selecting a certain number of a collection of \n",
    "    items from some pool, and then arranging them in a specific way such that two\n",
    "    items of the same type can be interchanged and the result is considered the same\n",
    "    \n",
    "    Arguments:\n",
    "    probs - a dictionary of probabilities of selecting each item\n",
    "    occurences - a dictionary for the number of selections of each desired symbol\n",
    "    \n",
    "    Returns:\n",
    "    prop -  the probability of selecting a certain number of characters of each type from\n",
    "            the probs dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtains the terms in the probability dictionary\n",
    "    terms = probs.keys()\n",
    "    \n",
    "    # Initializes the probability\n",
    "    prob = 1.0\n",
    "    \n",
    "    # Multiplies the independent probability of each character\n",
    "    for term in terms:\n",
    "        prob *= mp.power(probs[term], occurences[term])\n",
    "    \n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of typing Spamlet given that the probability distributions for the keys are the same as they are for those in Spamlet is 1.50127331056182e-227751\n"
     ]
    }
   ],
   "source": [
    "# Obtains the character dictionary and associated probability dictionary\n",
    "charDict = singleCharDecode(url)\n",
    "charProbs = dictProbs(charDict)\n",
    "\n",
    "weightedProb = prob_selection(charProbs, charDict)\n",
    "\n",
    "print(\"The probability of typing Spamlet given that the probability \" + \n",
    "      \"distributions for the keys are the same as they are for those in Spamlet is\", weightedProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we see that the probability of a monkey typing Spamlet with each of the 27-keys being equally probable, approximately $1.4854119E-264416$, is less than the probability that a monkey types Spamlet with each key having a probability of being hit equal to its probability of being selected out of Spamlet, approximately $1.5012733E-227751$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "In this question we find the joint-probability of tuples of keys in Spamlet, and then use the resulting probability distribution for pairs to determine the probability that a monkey types Spamlet following this distribution, typing pairs of keys at a time. Further, we note that if a monkey were to attempt to reconstruct Spamlet from tuples found in Spamlet, only the even tuples would on average contribute to the creation of Spamlet, where by \"even tuple\" we mean a tuple which has its second letter occur at an even place in Spamlet. For example, if the first sentence of Spamlet was \"A platform before the Castle,\" the even tuples would be \"a \", \"pl\", \"at\", \"fo\", \"rm\", etcetera, while \" p\", \"la\", \"tf\", etcetera would be odd tuples. From this we can indeed see that building Spamlet from tuples we must proceed by stacking even tuples on top of eachother, since the first tuple will always be even and any distinct tuple succeeding an even tuple will also be even. Hence, in determining the probabilities of occurrences, we only consider the even tuples in Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoCharsDecode(url):\n",
    "    \"\"\"Stores the occurences of even tuples in one dictionary, \n",
    "    and stores the total probabilities for all tuples in Spamlet\n",
    "    in another, then returns both dictionaries to the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "    \n",
    "    \n",
    "    #  Creates a dictionary for storing the even character tuples\n",
    "    tupleDict_even = {}\n",
    "    # Runs over all even pairs in Spamlet \n",
    "    for i in range(len(charlist)//2):\n",
    "        charPair = charlist[2*i]+charlist[2*i+1]\n",
    "\n",
    "        # Increments the count if a tuple appears in the dictionary, and adds it otherwise.\n",
    "        if charPair in tupleDict_even.keys():\n",
    "            tupleDict_even[charPair] += 1\n",
    "        else:\n",
    "            tupleDict_even[charPair] = 1\n",
    "    \n",
    "    # Creates a dictionary for storing all character tuples in Spamlet\n",
    "    tupleDict_full = {}\n",
    "    # Runs over all pairs in Spamlet \n",
    "    for i in range(len(charlist)-1):\n",
    "        charPair = charlist[i]+charlist[i+1]\n",
    "\n",
    "        # Increments the count if a tuple appears in the dictionary, and adds it otherwise.\n",
    "        if charPair in tupleDict_full.keys():\n",
    "            tupleDict_full[charPair] += 1\n",
    "        else:\n",
    "            tupleDict_full[charPair] = 1\n",
    "    \n",
    "    # Returns the even tuple occurences, and a probability dictionary for the total occurences.\n",
    "    return tupleDict_even, dictProbs(tupleDict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoCharsDecode_even(url):\n",
    "    \"\"\"Stores the joint probabilities of tuples of characters in a dictionary\n",
    "    and returns the result\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "    \n",
    "    # Creates a dictionary for storing character tuples\n",
    "    tupleDict = {}\n",
    "    # Runs over all pairs in Spamlet such that the 2nd term is even (denoting the 0th term as 1)\n",
    "    for i in range(len(charlist)//2):\n",
    "        charPair = charlist[2*i]+charlist[2*i+1]\n",
    "\n",
    "        # Increments the count if a tuple appears in the dictionary, and adds it otherwise.\n",
    "        if charPair in tupleDict.keys():\n",
    "            tupleDict[charPair] += 1\n",
    "        else:\n",
    "            tupleDict[charPair] = 1\n",
    "    \n",
    "    return tupleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDisplay(tupleProbs, size = 4):\n",
    "    \"\"\"Displays a test range of formatted probabilities\"\"\"\n",
    "    \n",
    "    # Creates a list of all lowercase letters as well as space\n",
    "    testChars = list(' abcdefghijklmnopqrstuvwxyz')\n",
    "    \n",
    "    print(\"Test Probabilities:\")\n",
    "    for char1 in testChars[:size]:\n",
    "        print('\\t', end = \"\")\n",
    "        for char2 in testChars[:size]:\n",
    "            pair = ''.join([char1,char2])\n",
    "            if pair in tupleProbs.keys():\n",
    "                print(pair + \":\", \"{:.4e}\".format(tupleProbs[pair]), end = '\\t')\n",
    "            else:\n",
    "                print(pair + \":\", \"{:.4e}\".format(0.0), end = '\\t')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of reconstructing Spamlet if pairs of keys are hit according to the even key distribution in Spamlet is 1.64706860331996e-207260\n",
      "Test Probabilities:\n",
      "\t  : 0.0000e+00\t a: 1.7582e-02\t b: 7.7194e-03\t c: 6.4743e-03\t\n",
      "\ta : 3.9734e-03\taa: 0.0000e+00\tab: 7.4704e-04\tac: 1.4941e-03\t\n",
      "\tb : 1.5157e-04\tba: 8.1200e-04\tbb: 4.3306e-05\tbc: 0.0000e+00\t\n",
      "\tc : 5.0885e-04\tca: 1.9596e-03\tcb: 0.0000e+00\tcc: 2.4901e-04\t\n"
     ]
    }
   ],
   "source": [
    "# Obtains a dictionary of even tuples in Spamlet along with one containing their probabilities\n",
    "tupleDict = twoCharsDecode_even(url)\n",
    "tupleProbs = dictProbs(tupleDict)\n",
    "\n",
    "# Obtains the probability of reconstructing Spamlet from the tuples\n",
    "tupleSelectionProb = prob_selection(tupleProbs, tupleDict)\n",
    "\n",
    "print(\"The probability of reconstructing Spamlet if pairs of keys \" + \n",
    "      \"are hit according to the even key distribution in Spamlet is\",tupleSelectionProb)\n",
    "testDisplay(tupleProbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we conclude that using the even tuple approach, the probability of a monkey typing Spamlet using a keyboard of tuples, where the probability of a key occuring is the same as its probability distribution in Spamlet, is approximately $1.6470686E-207260$, which is greater than the probability for single characters. Additionally, we have displayed the probabilities of certain test tuples in a square array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "In this question we determine the entropy associated with 2-key sequences in Spamlet and for words in Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shannon entropy of 2-key sequences in Spamlet in bits per character is: 7.454144936347158\n"
     ]
    }
   ],
   "source": [
    "# 2-key Entropy\n",
    "\n",
    "# Obtains a dictionary of even tuples in Spamlet along with one containing their probabilities\n",
    "tupleDict = twoCharsDecode_even(url)\n",
    "tupleProbs = dictProbs(tupleDict)\n",
    "\n",
    "# Calculates the shannon entropy for the tuples\n",
    "tupleEntropy = shannonEntropy(tupleProbs)\n",
    "\n",
    "print(\"The shannon entropy of 2-key sequences in Spamlet in bits per character is:\",tupleEntropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we find that the Shannon Entropy for 2-key sequences in Spamlet in bits per character is approximately 7.4541449."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeWords(url):\n",
    "    \"\"\"Reads the data from a url and decodes it into words before sorting it into a dictionary\"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "    \n",
    "    \n",
    "    # Joins the characters into words separated by spaces\n",
    "    text = ''.join(charlist)\n",
    "    \n",
    "    # Removes the spaces and stores the individual words into a list\n",
    "    wordList = str.split(text, sep = \" \")\n",
    "    # Creates a dictionary counting the number of times each word occurs\n",
    "    wordDict = {}\n",
    "    for word in wordList:\n",
    "        # Increments the count if a word appears in the dictionary, and adds it to the dictionary otherwise.\n",
    "        if word in wordDict.keys():\n",
    "            wordDict[word] += 1\n",
    "        else:\n",
    "            wordDict[word] = 1\n",
    "    \n",
    "    return wordDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shannon entropy of word sequences in Spamlet in bits per character is: 9.395778599888459\n"
     ]
    }
   ],
   "source": [
    "# Obtains a dictionary of words in Spamlet along with one containing their probabilities\n",
    "wordDict = decodeWords(url)\n",
    "wordProbs = dictProbs(wordDict)\n",
    "\n",
    "# Calculates the shannon entropy for the words in Spamlet\n",
    "wordEntropy = shannonEntropy(wordProbs)\n",
    "\n",
    "print(\"The shannon entropy of word sequences in Spamlet in bits per character is:\",wordEntropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we find that the Shannon Entropy of words in Spamlet in bits per character is approximately 9.395778."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "\n",
    "In this problem we attempt to generate text similar to Shakespeare through the use of weighted probability distributions of characters, tuples, words, and punctuation. Random phrases are reconstructed with each of these options (characters, tuples, or words) as the base building block to show how each step is more close to intelligible sentences than the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordAndPunct(url):\n",
    "    \"\"\"Reads the data from a url and decodes it into words and punctuation before sorting it into a dictionary\"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "    \n",
    "    # Initializes an array for punctuation\n",
    "    punct = [',','.',';',':','?','!']\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "    \n",
    "    punctuations = [c for c in data if (c in punct)]\n",
    "    \n",
    "    # Joins the characters into words separated by certain numbers of spaces\n",
    "    text = ''.join(charlist)\n",
    "    \n",
    "    # Removes the spaces and stores the individual words into a list along with the punctuation\n",
    "    wordAndPunctList = str.split(text)\n",
    "    wordAndPunctList.extend(punctuations)\n",
    "    \n",
    "    # Creates a dictionary counting the number of times each word and punctuation mark occurs\n",
    "    totalDict = {}\n",
    "    for word in wordAndPunctList:\n",
    "        # Increments the count if a word appears in the dictionary, and adds it to the dictionary otherwise.\n",
    "        if word in totalDict.keys():\n",
    "            totalDict[word] += 1\n",
    "        else:\n",
    "            totalDict[word] = 1\n",
    "    \n",
    "    return totalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randTermPhrase(probDict, min_length = 100, words = False):\n",
    "    \"\"\"Creates a phrase of a given minimum length using\n",
    "    probabilities associated with each terms (tuples or singular characters) in the dictionary.\"\"\"\n",
    "    \n",
    "    # Initializes a list for the terms in a phrase\n",
    "    phraseTerms = []\n",
    "    \n",
    "    # Normalizes the probabilities so that they sum to one\n",
    "    sum_Probs = sum(list(probDict.values()))\n",
    "    for term in probDict.keys():\n",
    "        probDict[term] = probDict[term]/sum_Probs\n",
    "    \n",
    "    # Adds tuples to the phrase list until it is longer than the min length\n",
    "    while (len(phraseTerms) < min_length):\n",
    "        \n",
    "        # Obtains a random tuple based on the probabilities in the dictionary\n",
    "        term = np.random.choice(list(probDict.keys()), p = list(probDict.values()))\n",
    "        \n",
    "        # Appends the last term\n",
    "        phraseTerms.append(term)\n",
    "        \n",
    "        # If the terms are words, add a space after each one\n",
    "        if words == True:\n",
    "            phraseTerms.append(' ')\n",
    "    \n",
    "    return ''.join(phraseTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randWordPunctPhrase(fullDict, wordDict, min_length = 50):\n",
    "    \"\"\"Creates a phrase of a given minimum length using\n",
    "    probabilities associated with each word in the dictionary.\"\"\"\n",
    "    \n",
    "    # Initializes arrays for punctuation and end punctuation of sentences\n",
    "    endPunct = ['.','?','!']\n",
    "    punct = [',','.',';',':','?','!']\n",
    "\n",
    "    # Initializes a list for the terms in a phrase\n",
    "    phraseTerms = []\n",
    "    \n",
    "    # Turns the occurences into probabilities for just the words \n",
    "    # and for the words along with punctuation\n",
    "    sum_totProbs = sum(list(fullDict.values()))\n",
    "    sum_wordProbs = sum(list(wordDict.values()))\n",
    "    for term in fullDict.keys():\n",
    "        fullDict[term] = fullDict[term]/sum_totProbs\n",
    "    for term in wordDict.keys():\n",
    "        wordDict[term] = wordDict[term]/sum_wordProbs\n",
    "    \n",
    "    # Initialize Sentence with a random first word and capitalizes it\n",
    "    term = np.random.choice(list(wordDict.keys()), p = list(wordDict.values()))\n",
    "    term = term.capitalize()\n",
    "    phraseTerms.append(term)\n",
    "    \n",
    "    # Adds words and punctuation to the phrase list until it is longer than the min length\n",
    "    # and it ends in a period, exclamation point, or question mark.\n",
    "    while (len(phraseTerms) < min_length or not (phraseTerms[-1] in endPunct)):\n",
    "        \n",
    "        # Ensures the first term in a sentence is a capitalized word\n",
    "        if phraseTerms[-1] in punct:\n",
    "            term = np.random.choice(list(wordDict.keys()), p = list(wordDict.values()))\n",
    "            if phraseTerms[-1] in endPunct:\n",
    "                term = term.capitalize()\n",
    "        else:\n",
    "            term = np.random.choice(list(fullDict.keys()), p = list(fullDict.values()))\n",
    "        \n",
    "        # Adds a space in front of the term if it is not a punctuation\n",
    "        if not(term in punct):\n",
    "            phraseTerms.append(' ')\n",
    "            \n",
    "        # Capitalizes single i's\n",
    "        if term == 'i':\n",
    "            term = term.capitalize()\n",
    "            \n",
    "        # Appends the last term\n",
    "        phraseTerms.append(term)\n",
    "    \n",
    "    return ''.join(phraseTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter Phrases:\n",
      "1: \"utd osktthemts yel aa   esenhurina ue ee    ne iannow sovinllmi sartm soux s tl rngteseorethe kirhio\"\n",
      "2: \"gtfoedwef mr asesfnosnhrtous  ehesid   dkrrreh  irisigd r y rgsovweg sttdl ooreoetnrc  armuessydh rf\"\n",
      "3: \"rhfnimwdft  eehr ibpii xh neieaoe  dwclllvhagvmta tpoie tl ri mestfheete n tgineh  puntroft iee shn \"\n",
      "\n",
      "\n",
      "Tuple Phrases:\n",
      "1: \"an a fe owasigke sh igs enfingbewiho cusy av tenle oley enotad nisndri hthr r  dutysllheiton as gvd ommo lor t csto s ri nfohisc illyo tndssanegheomooteraon f hi yoteatityodsg iaetonulrtin wh mpannois\"\n",
      "2: \"t  oen to  wswo ctkierm atitthreou aheamnitost m a bndro tenzzvdllkspai ouyo gblaneaplcoeteds ndde ihtutoaf ustena omeccthtldedeteai akietofrbhennshughasohoanisetglriarhimendwat shtoal tutol golanu  n\"\n",
      "3: \"weowdeatf voenncosm infaet a she no  d bitmaf t epe yequ we ertoanomormdonh verendye sou ber an  de anusagrif  mnig  i hixml fth pmiantesefoor avewial muswh se taunve tomuge le you ymm wct pett  serm \"\n",
      "\n",
      "\n",
      "Word Phrases:\n",
      "1: \"all did ugly fair and convert was know up goes your better killd what associated of protected quality and and hamlet no watch life it they that fortinbras to property hamlet report for my agreement me and your into good in too within polonius have that father other but pale \"\n",
      "2: \"inclination to these my project us read my memory upon king points watch of may drossy make i save peace i complying methinks that and the gaingiving gum no my about wed good thexterior blood son sum this the word bout a fair what together with canst love most sir \"\n",
      "3: \"down first of before with day too between you ophelia well heart of whats closely concerning shake and bed unseen it not outlives is bear that with thy am but what free gods eye him the when most thoughts thine players by so my meed to foe you electronically lady \"\n",
      "\n",
      "\n",
      "Formatted Word Phrases:\n",
      "1: \"Barnardo before horatio thou you portraiture or or, in my a. Requite as unbated hamlet, what, horatio of but crocodile stays asunder have time to, so throw to prevent where hamlet gutenberg proof the with on, tell argument the, iv even.\"\n",
      "2: \"Commendable of shame. Light without that at whats then kingsirs to wicked given patiently have will, satyr without certain his of answerest strange a horatio laertes and pastoral foundation seem carriages seems very the not upon mens and all iv fathers: most when you england, you sail.\"\n",
      "3: \"Any lord united forth all tot mourning. End much. You an, is maggots a your tis you will acquire. Senseless lesser in? At.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtains dictionaries of characters, tuples, andwords in Spamlet along with ones containing their probabilities\n",
    "charDict = singleCharDecode(url)\n",
    "charProbs = dictProbs(charDict)\n",
    "tupleDict = twoCharsDecode_even(url)\n",
    "tupleProbs = dictProbs(tupleDict)\n",
    "wordDict = decodeWords(url)\n",
    "wordProbs = dictProbs(wordDict)\n",
    "totalDict = wordAndPunct(url)\n",
    "\n",
    "\n",
    "print(\"Letter Phrases:\")\n",
    "for i in range(3):\n",
    "    print(str(i+1) + \": \\\"\" + str(randTermPhrase(charProbs)) + \"\\\"\")\n",
    "print('\\n')\n",
    "    \n",
    "print(\"Tuple Phrases:\")\n",
    "for i in range(3):\n",
    "    print(str(i+1) + \": \\\"\" + str(randTermPhrase(tupleProbs)) + \"\\\"\")\n",
    "print('\\n')\n",
    "\n",
    "print(\"Word Phrases:\")\n",
    "for i in range(3):\n",
    "    print(str(i+1) + \": \\\"\" + str(randTermPhrase(wordProbs, words = True)) + \"\\\"\")\n",
    "print('\\n')\n",
    "\n",
    "print(\"Formatted Word Phrases:\")\n",
    "for i in range(3):\n",
    "    print(str(i+1) + \": \\\"\" + str(randWordPunctPhrase(totalDict, wordDict)) + \"\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see when it is just characters the reconstructed phrases are nearly entirely gibberish, with it being difficult to descern even the shape of any words. As we move on to tuples the strings start to appear slightly more word-like, with \"she\", \"you\", and \"no\" appearing, but are still mostly unintelligible. Next, using words as the building block the phrases are now readable, and even appear to generate somewhat coherent phrases using the probability distribution of words in Spamlet. Finally, the addition of capitalizations and punctuation further aids in bringing the random phrases closer to the form of shakespearean text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions/Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
