{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phys 481 Fall 2021 Assignment 2: Spamlet\n",
    "### A.G. Swadling (30098501)\n",
    "### E.J. Thompson (30087678)\n",
    "### G.J. Gelinas (30085897)\n",
    "### T.J. Cey (30088060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries for numerical methods and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load libraries for reading from a url and handling large numbers\n",
    "import urllib.request\n",
    "import mpmath as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we investigated how to calculate probability and entropy by applying it to the likelihood of reproducing a stripped down version of Shakespeare's \"Hamlet\" (Spamlet) from random keystrokes. We first built an understanding of Shannon entropy by calculating the entropy of Spamlet in bits per character. This calculation also required us to calculate the probability of each character being typed, which was done by dividing the number of times a given character occurred by the total number of characters in Spamlet (including repeats). In the following two questions we examined the number of possible sequences the same length as Spamlet that could be produced, and the probability that a given sequence would be Spamlet. This was done considering random strokes on a keyboard where every character key has equal probability of being pressed, and for where the probability of a character key being pressed was equal to the probability distribution in Spamlet.\n",
    "\n",
    "How the probability distribution and entropy would change if we considered groupings of characters opposed to individual characters was also examined. First the joint probability of a given character pair being produced was found, followed by the probability of producing Spamlet with this distribution. This was compared to what was found for individual characters. The probabilities found for character pairs were then used to calculate the associated Shannon entropy, which was then extended to full words. The effects of differing entropies observed for character, pair, and full word combinations were shown when we tried to construct Shakespeare like sentences from random combinations of characters, character pairs, full words, and word groupings from Spamlet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question we determine the Shannon Entropy of Spamlet in bits per character, using the probabilities of different characters occurring in Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonEntropy(probs):\n",
    "    \"\"\"Returns the shannon entropy associated with a collection of probabilities\"\"\"\n",
    "    \n",
    "    # Obtains the probability associated with all the items in the probs dictionary\n",
    "    prob_values = list(probs.values())\n",
    "    \n",
    "    # Calculates the shannon entropy\n",
    "    entropy = -sum(np.log2(prob_values)*prob_values)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictProbs(itemDict):\n",
    "    \"\"\"Returns a dictionary of probabilities associated with the occurrences of specified items in a file\"\"\"\n",
    "    \n",
    "    # Total number of occurrences\n",
    "    total = sum(itemDict.values())\n",
    "    \n",
    "    # Initializes probability dictionary\n",
    "    probs = {}\n",
    "    \n",
    "    # Gets the count of each character and adds its simple probability to the array\n",
    "    for item in itemDict.keys():\n",
    "        probs[item] = (1.0*itemDict[item]/total)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charDecoder(url):\n",
    "    \"\"\"Reads the data from a url and decodes it into characters. \n",
    "    Letters are made lower-case and added to a list along with spaces\n",
    "    and newline characters recoded as spaces. The collection of decoded\n",
    "    bytedata is also returned in case it is needed for other work.\"\"\"\n",
    "    \n",
    "    # Retrieves bytedata and decodes it into characters\n",
    "    bytedata = urllib.request.urlopen( url ).read()\n",
    "    data = bytedata.decode()\n",
    "\n",
    "    # Creates a list to contain all characters in the data \n",
    "    charlist = []\n",
    "    # Adds characters and spaces, as well as single newlines as spaces, to our character list\n",
    "    for char in data:\n",
    "        if (char.isalpha()):\n",
    "            charlist.append(char.lower())\n",
    "        elif  (char == ' ' or char == '\\n') and charlist[-1] != ' ': # Removes double spaces\n",
    "            charlist.append(' ')\n",
    "            \n",
    "    return charlist, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurenceDict(termList, N = 1, words = False):\n",
    "    \"\"\"Creates a dictionary for the number of times \n",
    "    a collection of N terms occurs in a row in the inputted list.\n",
    "    If the inputted list is made up of words, spaces are added between \n",
    "    consecutive terms.\"\"\"\n",
    "    \n",
    "    # Creates a dictionary counting the number of times each term occurs in the list\n",
    "    termDict = {}\n",
    "    # Ranges over the termlist until there are not N terms left\n",
    "    for i in range(len(termList)-(N-1)):\n",
    "        if words:\n",
    "            # Adjoins the next N-1 terms to a string, followed by a space, then adds the \n",
    "            # Nth term without any space\n",
    "            termString = ''.join([(termList[i+j]+\" \") for j in range(N-1)])\n",
    "            termString += termList[i+(N-1)]\n",
    "        else:\n",
    "            # Adjoins the next N terms directly\n",
    "            termString = ''.join([(termList[i+j]) for j in range(N)])\n",
    "\n",
    "        # Increments the item's dictionary value if it is already stored, \n",
    "        # and initializes it at one otherwise\n",
    "        if termString in termDict.keys():\n",
    "            termDict[termString] += 1\n",
    "        else:\n",
    "            termDict[termString] = 1\n",
    "    \n",
    "    return termDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain spamlet data and character dictionary for future use\n",
    "url = r'http://www.gutenberg.org/files/1524/1524-0.txt'\n",
    "charList, dataCollection = charDecoder(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of Spamlet in bits per character is: 4.095554914480837\n"
     ]
    }
   ],
   "source": [
    "# Obtains the character dictionary and associated probability dictionary for calculating the shannon entropy\n",
    "charDict = occurenceDict(charList)\n",
    "charProbs = dictProbs(charDict)\n",
    "entropy = shannonEntropy(charProbs)\n",
    "\n",
    "print(\"The entropy of Spamlet in bits per character is:\", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we observe that the Shannon Entropy for Spamlet in bits per character is approximately 4.096."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 2:\n",
    "\n",
    "In this question we determine the probability of a monkey typing Spamlet on a keyboard consisting of the 26 letter characters, and a spacebar, where all 27 characters are equally probable. In particular, we determine the number of 27-key sequences of length 184730 (the length of Spamlet after removing double spaces), and we determine the probability of any one of these sequences being typed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_sequences(num_options, length):\n",
    "    \"\"\"Returns the number of sequences of a certain length given that each entry has num_options choices\"\"\"\n",
    "    \n",
    "    return mp.power(num_options,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_total(num_options, length):\n",
    "    \"\"\"Returns the probability of obtaining a particular sequence of characters of length 'length'\n",
    "    from a selection of 'num_options' symbols.\"\"\"\n",
    "    \n",
    "    return mp.power(num_options, -length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sequences of length 184730 made up of 27-keys is 6.73213923799414e+264415\n",
      "The probability of any one such sequence occurring is 1.4854119391297e-264416\n"
     ]
    }
   ],
   "source": [
    "# Obtains the length of the character dictionary found in Question 1 for Spamlet\n",
    "length = sum(charDict.values())\n",
    "\n",
    "# Obtains the number of sequences and the probability of any given sequence \n",
    "# of length equal to Spamlet for the 26 letter characters and space\n",
    "sequenceNum = num_sequences(27, length)\n",
    "probTot = prob_total(27, length)\n",
    "\n",
    "print(\"The number of sequences of length\", length, \"made up of 27-keys is\", sequenceNum)\n",
    "print(\"The probability of any one such sequence occurring is\", probTot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have that if the monkey presses the 27-keys with equal probability, the number of possible sequences is approximately 6.732ùê∏+264415, with each sequence having a probability of 1.485ùê∏-264416 of being typed at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "We now investigate how the probability of a monkey typing Spamlet changes if the key probabilities are not uniform but instead the probability of hitting any given key is the same as the probability of selecting that key at random out of Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_selection(probs, occurrences):\n",
    "    \"\"\"\n",
    "    Returns the probability of selecting a specific sequence of characters\n",
    "    with weighted probabilities.\n",
    "    \n",
    "    Arguments:\n",
    "    probs - a dictionary of probabilities of selecting each item\n",
    "    occurrences - a dictionary for the number of selections of each desired symbol\n",
    "    \n",
    "    Returns:\n",
    "    prob -  the probability of selecting a certain number of characters of each type from\n",
    "            the probs dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Obtains the terms in the probability dictionary\n",
    "    terms = occurrences.keys()\n",
    "    \n",
    "    # Initializes the probability\n",
    "    prob = 1.0\n",
    "    \n",
    "    # Multiplies the independent probability of each character\n",
    "    for term in terms:\n",
    "        prob *= mp.power(probs[term], occurrences[term])\n",
    "    \n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of typing Spamlet given that the probability distributions for the keys are the same as they are for those in Spamlet is 1.50127331056182e-227751\n"
     ]
    }
   ],
   "source": [
    "# Obtains the weighted probability associated with typing Spamlet with the character dictionary.\n",
    "weightedProb = prob_selection(charProbs, charDict)\n",
    "\n",
    "print(\"The probability of typing Spamlet given that the probability \" + \n",
    "      \"distributions for the keys are the same as they are for those in Spamlet is\", weightedProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we see that the probability of a monkey typing Spamlet with each of the 27-keys being equally probable, which is approximately 1.485ùê∏-264416, is less than the probability that a monkey types Spamlet with each key having a probability of being hit determined by the key occurrences in Spamlet, which yielded a probability of approximately 1.501ùê∏-227751."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "In this question we find the joint-probability of 2-key sequences in Spamlet, and then use the resulting probability distribution for pairs to determine the probability that a monkey types Spamlet following this distribution, typing pairs of keys at a time. To determine the probability of 2-key sequences we used the number of occurrences for all adjacent sequences of 2-keys, including spaces, in the Spamlet document. But, in order to determine the probability of reconstructing Spamlet we need to use the occurrences of the even pairs, where by \"even pair\" we mean a pair which has its second letter occur at an even place in Spamlet. For example, if the first sentence of Spamlet was \"A platform before the Castle,\" the even pairs would be \"a \", \"pl\", \"at\", \"fo\", \"rm\", etcetera, while \" p\", \"la\", \"tf\", etcetera would be odd pairs. From this example, we can indeed see that in building Spamlet from pairs we must proceed by stacking even pairs on top of each other, since the first pair will always be even and any distinct pair succeeding an even pair will also be even. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoCharsDict(charList):\n",
    "    \"\"\"Stores the occurrences of even 2-pairs in one dictionary, \n",
    "    and stores the total probabilities for all 2-pairs in Spamlet\n",
    "    in another, then returns both dictionaries to the user.\n",
    "    \n",
    "    Arguments:\n",
    "    charList - list of characters to sort\n",
    "    \n",
    "    Returns:\n",
    "    pairDict_even - a dictionary of the number of occurrences of all even pairs\n",
    "    dictProbs(pairDict_full) - a dictionary of the probability of all pairs\n",
    "    \"\"\"\n",
    "    \n",
    "    #  Creates a dictionary for storing the even character 2-pairs\n",
    "    pairDict_even = {}\n",
    "    # Runs over all even pairs in Spamlet \n",
    "    for i in range(len(charList)//2):\n",
    "        charPair = charList[2*i]+charList[2*i+1]\n",
    "\n",
    "        # Increments the count if a pair appears in the dictionary, and adds it otherwise.\n",
    "        if charPair in pairDict_even.keys():\n",
    "            pairDict_even[charPair] += 1\n",
    "        else:\n",
    "            pairDict_even[charPair] = 1\n",
    "    \n",
    "    # Creates a dictionary for storing all character 2-pairs in Spamlet\n",
    "    pairDict_full = occurenceDict(charList, N = 2)\n",
    "    \n",
    "    # Returns the even pair occurrences, and a probability dictionary for the total occurrences.\n",
    "    return pairDict_even, dictProbs(pairDict_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDisplay(pairProbs, size = 4):\n",
    "    \"\"\"Displays a test range of formatted probabilities\n",
    "    in a square array based on the characters paired together.\"\"\"\n",
    "    \n",
    "    # Creates a list of all lowercase letters as well as space\n",
    "    testChars = list(' abcdefghijklmnopqrstuvwxyz')\n",
    "    \n",
    "    print(\"Test Probabilities:\")\n",
    "    # Adjoins the 'size' different characters into 'size^2' different pairs\n",
    "    # and prints the resulting probability of each pair in a square array beside them\n",
    "    for char1 in testChars[:size]:\n",
    "        print('\\t', end = \"\")\n",
    "        for char2 in testChars[:size]:\n",
    "            pair = ''.join([char1,char2])\n",
    "            if pair in pairProbs.keys():\n",
    "                print(pair + \":\", \"{:.4e}\".format(pairProbs[pair]), end = '\\t')\n",
    "            else:\n",
    "                print(pair + \":\", \"{:.4e}\".format(0.0), end = '\\t')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of reconstructing Spamlet if pairs of keys are hit according to the even key distribution in Spamlet is 4.78319487722973e-207316\n",
      "Test Probabilities:\n",
      "\t  : 0.0000e+00\t a: 1.7729e-02\t b: 7.9468e-03\t c: 6.4852e-03\t\n",
      "\ta : 3.9896e-03\taa: 0.0000e+00\tab: 6.7667e-04\tac: 1.5915e-03\t\n",
      "\tb : 1.5699e-04\tba: 7.1997e-04\tbb: 5.9547e-05\tbc: 0.0000e+00\t\n",
      "\tc : 5.0344e-04\tca: 1.8784e-03\tcb: 0.0000e+00\tcc: 2.4901e-04\t\n"
     ]
    }
   ],
   "source": [
    "# Obtains a dictionary of even 2-pairs in Spamlet along with one containing their probabilities\n",
    "pairDict_even, totalPairProbs = twoCharsDict(charList)\n",
    "\n",
    "# Obtains the probability of reconstructing Spamlet from the 2-pairs\n",
    "pairSelectionProb = prob_selection(totalPairProbs, pairDict_even)\n",
    "\n",
    "print(\"The probability of reconstructing Spamlet if pairs of keys \" + \n",
    "      \"are hit according to the even key distribution in Spamlet is\",pairSelectionProb)\n",
    "testDisplay(totalPairProbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we conclude that using 2-key sequences, the probability of a monkey typing Spamlet using a keyboard of pairs, where the probability of a key occurring is the same as its probability distribution in Spamlet, is approximately 4.783ùê∏-207316. Consequently, this probability is greater than the probability for single characters, both in the uniform case and the weighted case where the distributions of characters in Spamlet were used. Additionally, we have displayed the probabilities of certain test pairs in a square array to illustrate examples of the calculated probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "In this question we determine the entropy associated with 2-key sequences in Spamlet and for words in Spamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shannon entropy of 2-key sequences in Spamlet in bits per character is: 7.455948161245874\n"
     ]
    }
   ],
   "source": [
    "# 2-key Entropy\n",
    "# Calculates the shannon entropy for the pairs using the probability dictionary calculated in question 4\n",
    "pairEntropy = shannonEntropy(totalPairProbs)\n",
    "\n",
    "print(\"The shannon entropy of 2-key sequences in Spamlet in bits per character is:\",pairEntropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we find that the Shannon Entropy for 2-key sequences in Spamlet in bits per character is approximately 7.456, which is greater than the Shannon Entropy associated with single characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeWords(charList, numWords = 1):\n",
    "    \"\"\"Adjoins the character in the character list into words, \n",
    "    and then sorts them into a dictionary of occurrences. If numWords is more than 1,\n",
    "    adjacent words are put together.\"\"\"\n",
    "    \n",
    "    # Joins the characters into words separated by spaces\n",
    "    text = ''.join(charList)\n",
    "    \n",
    "    # Removes the spaces and stores the individual words into a list\n",
    "    wordList = str.split(text, sep = \" \")\n",
    "    # Creates a dictionary counting the number of times each word occurs\n",
    "    wordDict = occurenceDict(wordList, N = numWords, words = True)\n",
    "    \n",
    "    return wordDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shannon entropy of word sequences in Spamlet in bits per character is: 9.395778599888459\n"
     ]
    }
   ],
   "source": [
    "# Obtains a dictionary of words in Spamlet along with one containing their probabilities\n",
    "wordDict = decodeWords(charList)\n",
    "wordProbs = dictProbs(wordDict)\n",
    "\n",
    "# Calculates the shannon entropy for the words in Spamlet\n",
    "wordEntropy = shannonEntropy(wordProbs)\n",
    "\n",
    "print(\"The shannon entropy of word sequences in Spamlet in bits per character is:\",wordEntropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we find that the Shannon Entropy of words in Spamlet in bits per character is approximately 9.396. In particular, we find that the Shannon Entropy of words in Spamlet is greater than the Shannon Entropy for both 2-key sequences and single characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "\n",
    "In this problem we attempt to generate text similar to Shakespeare through the use of weighted probability distributions of characters, pairs, words, and punctuation. Random phrases are reconstructed with each of these options (characters, pairs, or words) as the base building block to show how each step is closer to intelligible sentences than the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordAndPunct(charList, data):\n",
    "    \"\"\"Adjoins the character in the character list into words,\n",
    "    and appends punctuation before sorting them into a dictionary\n",
    "    of occurrences in Spamlet.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializes an array for punctuation\n",
    "    punct = [',','.',';',':','?','!']\n",
    "    \n",
    "    # Creates a list of the occurrences of punctuation in Spamlet\n",
    "    punctuations = [c for c in data if (c in punct)]\n",
    "    \n",
    "    # Joins the characters into words separated by certain numbers of spaces\n",
    "    text = ''.join(charList)\n",
    "    \n",
    "    # Removes the spaces and stores the individual words into a list along with the punctuation\n",
    "    wordAndPunctList = str.split(text)\n",
    "    wordAndPunctList.extend(punctuations)\n",
    "    \n",
    "    # Creates a dictionary counting the number of times each word and punctuation mark occurs\n",
    "    totalDict = occurenceDict(wordAndPunctList)\n",
    "    \n",
    "    return totalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randTermPhrase(termDict, min_length, words = False):\n",
    "    \"\"\"Creates a phrase of a given minimum length using probabilities \n",
    "    associated with each term (for example pairs or singular characters) in the dictionary.\n",
    "    \n",
    "    Arguments:\n",
    "    probDict - dictionary of probabilities of the terms used to generate our phrase\n",
    "    min_length - the minimum number of terms in a generated phrase\n",
    "    words - boolean describing whether the terms in probDict are whole words or not\n",
    "    \n",
    "    Returns:\n",
    "    finalPhrase - the string obtained by concatenating the generated terms\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializes a list for the terms in a phrase\n",
    "    phraseTerms = []\n",
    "    \n",
    "    # Obtains a dictionary of probabilities for the terms\n",
    "    probDict = dictProbs(termDict)\n",
    "    \n",
    "    # Adds pairs to the phrase list until it is longer than the min length\n",
    "    while (len(phraseTerms) < min_length):\n",
    "        \n",
    "        # Obtains a random pair based on the probabilities in the dictionary\n",
    "        term = np.random.choice(list(probDict.keys()), p = list(probDict.values()))\n",
    "        \n",
    "        # Appends the last term\n",
    "        phraseTerms.append(term)\n",
    "        \n",
    "        # If the terms are words, add a space after each one\n",
    "        if words == True:\n",
    "            phraseTerms.append(' ')\n",
    "    \n",
    "    # Concatenates the terms into a single string\n",
    "    finalPhrase = ''.join(phraseTerms)\n",
    "    \n",
    "    return finalPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randWordPunctPhrase(fullDict, wordDict, min_length = 50):\n",
    "    \"\"\"Creates a phrase of a given minimum length using\n",
    "    probabilities associated with each word in the dictionary\n",
    "    as well as the probabilities of punctuation.\n",
    "    \n",
    "    Arguments:\n",
    "    fullDict - dictionary of all words and punctuation along with their occurrences\n",
    "    wordDict - dictionary of all words with their occurrences\n",
    "    min_length - the minimum number of words and punctuation points in the generated phrase\n",
    "    \n",
    "    Returns:\n",
    "    finalPhrase - the string obtained by concatenating the generated words and punctuation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializes arrays for punctuation and end punctuation of sentences\n",
    "    endPunct = ['.','?','!']\n",
    "    punct = [',','.',';',':','?','!']\n",
    "\n",
    "    # Initializes a list for the terms in a phrase\n",
    "    phraseTerms = []\n",
    "    \n",
    "    # Turns the occurrences into probabilities for just the words \n",
    "    # and for the words along with punctuation\n",
    "    fullProbDict = dictProbs(fullDict)\n",
    "    wordProbDict = dictProbs(wordDict)\n",
    "    \n",
    "    # Initialize Sentence with a random first word and capitalizes it\n",
    "    term = np.random.choice(list(wordProbDict.keys()), p = list(wordProbDict.values()))\n",
    "    term = term.capitalize()\n",
    "    phraseTerms.append(term)\n",
    "    \n",
    "    # Adds words and punctuation to the phrase list until it is longer than the min length\n",
    "    # and it ends in a period, exclamation mark, or question mark.\n",
    "    while (len(phraseTerms) < min_length or not (phraseTerms[-1] in endPunct)):\n",
    "        \n",
    "        # Takes a random word if the last term was a punctuation, and capitalizes it\n",
    "        # if it was also an ending punctuation (i.e. period, exclamation mark, or question mark)\n",
    "        if phraseTerms[-1] in punct:\n",
    "            term = np.random.choice(list(wordProbDict.keys()), p = list(wordProbDict.values()))\n",
    "            if phraseTerms[-1] in endPunct:\n",
    "                term = term.capitalize()\n",
    "        else:\n",
    "            term = np.random.choice(list(fullProbDict.keys()), p = list(fullProbDict.values()))\n",
    "        \n",
    "        # Adds a space in front of the term if it is not a punctuation\n",
    "        if not(term in punct):\n",
    "            phraseTerms.append(' ')\n",
    "            \n",
    "        # Capitalizes single i's\n",
    "        if term == 'i':\n",
    "            term = term.capitalize()\n",
    "            \n",
    "        # Appends the last term\n",
    "        phraseTerms.append(term)\n",
    "    \n",
    "    # Joins the words and punctuations into a single string\n",
    "    finalPhrase = ''.join(phraseTerms)\n",
    "    \n",
    "    return finalPhrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phraseGenerator(termDict, termType, min_termNum = 50, num_phrases = 3):\n",
    "    \"\"\"Generates random phrases using a dictionary of terms and their occurrences,\n",
    "    and prints them to the screen.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks whether the inputted term dictionary is in words\n",
    "    if termType == \"Word\" or termType == \"Double Word\":\n",
    "        areWords = True\n",
    "    else:\n",
    "        areWords = False\n",
    "    \n",
    "    # Decomposes termDict if the terms being printed are formatted words\n",
    "    if termType == \"Formatted Word\":\n",
    "        totalDict, wordDict = termDict\n",
    "    \n",
    "    # Prints phrases reconstructed from term probabilities\n",
    "    print(termType + \" Phrases:\")\n",
    "    for i in range(num_phrases):\n",
    "        if termType == \"Formatted Word\":\n",
    "            print(str(i+1) + \": \\\"\" + str(randWordPunctPhrase(totalDict, wordDict)) + \"\\\"\")\n",
    "        else:\n",
    "            print(str(i+1) + \": \\\"\" + str(randTermPhrase(termDict, min_termNum, words = areWords)) + \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter Phrases:\n",
      "1: \"gl ioeitndilsto rley h vroo rohe  we r ohee niofia\"\n",
      "2: \"r itgg mh f  dalitit  teu dste eaohrtrureunsssxrdc\"\n",
      "3: \" ae si  rhaiont cscu toi y soiboavdn i psutoehd ui\"\n",
      "\n",
      "\n",
      "Pair Phrases:\n",
      "1: \"liitee olist ms a noy f ushso lasr smaths  f tnt h oelasnditrdor tallehe orie  nceheieguhopa thaomn \"\n",
      "2: \"thmelaexon nic qshofcu dguishe fthd al camexe soseeala ctoetkeutve mteesmyire ha tacea crmeee pp fh \"\n",
      "3: \"usagdoat h darourrinbld ironth nw  aow his ausannole ievr threbo nouhte rgvdisomhenscat stdrttni b p\"\n",
      "\n",
      "\n",
      "Word Phrases:\n",
      "1: \"i taxes the his argues can food goodly needs first of without lewdness that to hot where till an pronounced speak speak shows arm use \"\n",
      "2: \"mould dear confess their not say kneels elsinore license throat our come waits something enter very ever literary did o whispers are though far delay \"\n",
      "3: \"kissd live season hamlet have who come law pleasure hamlet give ophelia that overthrown one and int him or a held the accident to have \"\n",
      "\n",
      "\n",
      "Double Word Phrases:\n",
      "1: \"have all him the and cleave to commend one face revenge ghost and unfold good friends what judgment through your a flagon man shall thousand pound in the so shall her golden honey of that i a whit exit horatio i warrant him home first lord by his phrase or \"\n",
      "2: \"the other go to your revenge the first into madness liege i as the what ceremony stick our my way near the castle dramatis my thoughts for to like eager king follow please you damnd fingers did squeak us go dry as she please same skull your majesty his passage \"\n",
      "3: \"prepare thyself speech well acres on in form how ist be blesd i eat fame the lack a and how part a beards that inward service of me mouth and to my mark it night if be a such a heard that war why thy asking had neither king and \"\n",
      "\n",
      "\n",
      "Formatted Word Phrases:\n",
      "1: \"Hamlet better hamlet of wwwgutenbergorg word the, our little. Enter a to his, thoughts laertess a hamlet must a such up b in? I from that, no no solemn no indeed to or sweet you lack project.\"\n",
      "2: \"Easy but these whether brains did to, my active but have he beauty that some quick not she the fair. In o. What have; the he.\"\n",
      "3: \"A your nothing pound nay. Set must I speaks vows gutenberg, know to me us heard whose we, of as, my his indicate lord exit law their the tongue thine king watch such, and ophelia redeliver he a mournd to, do the, god that love I do the.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtains dictionaries for the number of occurances of pairs of words in Spamlet.\n",
    "doubleWordDict = decodeWords(charList, numWords = 2)\n",
    "\n",
    "# Obtains a dictionary for the number of occurrences of single words and punctuation\n",
    "# using the character list and collection of data obtained in question 1\n",
    "totalDict = wordAndPunct(charList, dataCollection)\n",
    "\n",
    "# Creates an array of the different term dictionaries in this assignment, and their names for printing\n",
    "dictArray = [charDict, totalPairProbs, wordDict, doubleWordDict, (totalDict, wordDict)]\n",
    "typeArray = [\"Letter\", \"Pair\", \"Word\", \"Double Word\", \"Formatted Word\"]\n",
    "\n",
    "\n",
    "for i in range(len(dictArray)):\n",
    "    phraseGenerator(dictArray[i], typeArray[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when it is just characters the reconstructed phrases are nearly entirely gibberish, with it being difficult to discern even the shape of any words. As we move on to pairs, the strings start to appear slightly more word-like, with \"she\", \"you\", and \"no\" appearing, but are still mostly unintelligible. Next, using words as the building block the phrases are now readable, and even appear to generate somewhat coherent phrases using the probability distribution of words in Spamlet. Using pairs of adjacent words in Spamlet the phrases start to read more like Shakespeare, with the structure of the phrases making more sense as a whole. Finally, the addition of capitalizations and punctuation further aids in bringing the random phrases closer to the form of Shakespearean text, although as this is done with the single words and not the pairs, the structure of the phrases is not as coherent as the double word phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions/Summary\n",
    "\n",
    "This assignment focused on probability and entropy calculations specifically regarding a monkey reproducing Spamlet through randomly hitting a keyboard numerous times. To begin, the Shannon Entropy of Spamlet was found to be 4.096 bits per character in Question 1. Following this the probability of reproducing Spamlet was found to be 1.485ùê∏-264416 when there is an equally likely chance to hit each of the 27 keys. To do this the number of sequences of length 184730 made up of 27 keys, each with a probability of 1/27 of being selected, was found to be 6.732ùê∏+264415. From that point the likelihood of producing the exact key sequence of Spamlet was determined to be the inverse of the number of sequences since the probability distribution for the keys is uniform. Question 3 examined the probability of reproducing Spamlet, again through random key strokes, however this time the likelihood of selecting each key was not equal. The probability of each key occurring in Spamlet was determined and used to construct probability distributions for the 27 keys. Then, the overall probability of a Spamlet reproduction using these determined key distributions was calculated to be 1.501ùê∏‚àí227751. It can be seen that it is more likely for a monkey to type Spamlet when the probability of hitting each key is specified by the distribution of keys in Spamlet itself, instead of a uniform distribution of keys. Next the joint-probability of 2-key sequences in Spamlet was determined for each sequence of adjacent keys that appeared in Spamlet. From this the probability of a monkey producing Spamlet through hitting pairs of keys according to this distribution was determined to be 4.783ùê∏-207316. Evidently, we find that with this alteration the probability of a monkey reproducing Spamlet once again increases as compared to both of the single key probabilities (uniform and non-uniform). Finally the Shannon Entropy of 2-key sequences and words in Spamlet were determined to be 7.456 and 9.396 bits per character, respectively. Hence, throughout we observe that as the terms we are selecting become more complex (characters to pairs of characters to full words), their associated Shannon Entropy increases. This follows intuitively from the fact that selecting a random word from all the possibilities in Spamlet provides more information than the selection of a 2-key sequence, and the selection of the 2-key sequence provides more information than single character selections. Indeed, the number of single characters is $27$, the number of 2-key sequences is $27\\cdot 27$, and the number of words would be strictly greater than the number of 2-key sequences, being formed from sequences of size greater than or equal to 1. Thus, the number of possibilities at each step increases. To conclude, throughout this assignment a thorough analysis of the probability of a random production of Spamlet by typing monkeys, simulating the notion of random processes, was done successfully. \n",
    "\n",
    "\n",
    "In optional question 6, a random generation of characters, 2-key sequences, words, and pairs of words was used to create a section of text that, although largely incoherent, resembled Spamlet. Here it was found that to achieve the most coherent and sensible result, it was useful to pull pairs of adjacent words from Spamlet and include simple grammar such as capitalization and punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
